# Generic configurations

## Diffusion config
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|diffusion_dropout | float = 0.0 | dropout rate of diffusion model |
|num_sample |int = 1 | Number of samples which are generated by randomly dropout output of model |
|learn_sigma | bool = False | Whether learning sigma of reverse distribution |
|sigma_small | bool = False | In case of fixed sigma, using sigma small means fix it to beta. In contrast, larga sigma means the tilde beta |
|class_cond | bool = False | Whether adding class information to model |
|diffusion_steps | int = 1000 | Number of diffusion steps |
|noise_schedule | str = 'linear' | Noise schedule to use, is one of three options: linear, cosine, exponential |
|timestep_respacing | str = "" | Use for DDIM generating |
|use_kl | bool = False | Whether using kl as loss function |
|predict_xstart | bool = False | Predicting xstart or epsilon |
|rescale_timesteps | bool = True | Rescaling time step to fix range, very useful when experiments with different diffusion steps |
|use_checkpoint | bool = False | If true, model will be loaded from the checkpoint path |
|use_scale_shift_norm | bool = True | |
|weight_clipping | bool = False ||

## Model config
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|image_size | int = 64 | Input image size |
|num_channels | int = 128 | |
|num_res_blocks | int = 2 | |
|num_heads | int = 4 | |
|num_heads_upsample | int = -1 | |
|attention_resolutions | str = "16,8" | |
|dropout | float = 0.0 | |

## Log config
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|OPENAI_LOGDIR | str = "" | Path to log folder |
|OPENAI_LOG_FORMAT | str = "stdout" | Kind of logs |

# Train Configurations
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|data_dir| str="" | Path to training data folder |
|schedule_sampler| str="uniform" | Strategy to sample t |
|lr| float=1e-4 | Learning rate |
|weight_decay| float=0.0 | Weight decay parameter |
|lr_anneal_steps| int=0 | Starting anneal step |
|batch_size| int=1 | Batch size |
|microbatch| int=-1 | Microbatch size, incase of -1, disable  microbatches|
|ema_rate| str="0.9999" | Exponential moving average |
|log_interval| int=10 ||
|save_interval| int=10000 ||
|resume_checkpoint| str="" |Checkpoint path|
|use_fp16| bool=False ||
|fp16_scale_growth| float=1e-3 ||

# Sample Configurations
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|clip_denoised| bool=True ||
|num_samples| int=10000 ||
|batch_size| int=16 ||
|use_ddim| bool=False ||
|model_path| str="" |Path to model checkpoint|

# Lipschitz calculation Configurations
|Argument            | Type hint, default value | Help |
|--------------------|--------------------------|------|
|clip_denoised| bool=True ||
|num_loops| int=10 ||
|batch_size| int=16 ||
|use_ddim| bool=False ||
|model_path| str="" |Path to model checkpoint|

# Example python config code
```python
os.environ["MODEL_FLAGS"] = "--image_size 32 --num_channels 128 --num_res_blocks 3 --dropout 0.1"
os.environ["DIFFUSION_FLAGS"] = "--diffusion_steps 200 --noise_schedule exponential --diffusion_dropout 0.1 --num_sample 10"
os.environ["TRAIN_FLAGS"] = "--lr 1e-4 --batch_size 64 --save_interval 10000"
os.environ["OPENAI_LOGDIR"] = "log"
os.environ["OPENAI_LOG_FORMAT"] = "csv"
```
